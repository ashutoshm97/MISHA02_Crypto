{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Oi4hMID9x-",
        "outputId": "67d8b3aa-c6a8-4c66-9407-4029e3b3e163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtJAIJ08EXjg",
        "outputId": "a4a6aaab-e3b9-4501-b721-b149382d0e6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNMGNzJ1E21b",
        "outputId": "aefda234-6ad9-4385-ab4c-1729d3c06691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.2)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, responses, multiprocess, datasets, evaluate\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 evaluate-0.4.1 multiprocess-0.70.16 responses-0.18.0 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a2e074f85594fba8e55097a3e3c5856",
            "4329fbef8fd044839b19df6f564315b2",
            "a5ba9cf403ec4b08a813235785ab0083",
            "8c57c3b6962c4028ac703d9ce6df74d9",
            "b3968415d12b40438094e671ae3f8031",
            "b455ef61e1c746f3a7d6f21af943059b",
            "61f9b83753754282951ed99efb97278a",
            "41efd05011c44826ad0ad60ad677fecc",
            "fcabe035fc5e42f99b1dd925d0b49703",
            "bd25f2e1d9ba4807b78d392893539621",
            "8387dbcf27fc4d6eb7c90ab9feb29486",
            "a3da6a66ddcd4238b1027611781757ea",
            "3213eae0f2ad416bbf6d708363bd910d",
            "53903f01046d46c0b7422c0750625de9",
            "6fa771f3f04e4366bbd4e1699bf413d3",
            "5dc9169fbcc047bdb49b0e641391fa30",
            "ff4bfe10dc6247d0a0b516be82df087d",
            "6ed9bcc8ae8c4f019ff212c54a9f9208",
            "8483462bb8f94f0dbe62c11b319b311d",
            "844145daecd54108bdc9bae803c23b41",
            "f032b765cbf14b9b895b98a37888fac8",
            "9dd27d136c164798b812b8d1abc10e89",
            "0888f3e360ce46a39637d460d584c61d",
            "0c41a5d3a1894f1db4f903e5c98b172c",
            "71e84a3643f54ad2942d931c06037f38",
            "ac29afc81d524eccb5749d65edbf703d",
            "8d37784e34fd42cf8efb71260cdc27e5",
            "5bc4f82403ba4591bcb7c2d5b162c1a0",
            "0e96e5d9810d45f386d4431c1eab815f",
            "94307407414f4dc1b2a1457b3cd105c2",
            "dadf4c8a87f148f2aa891e369ec104a5",
            "a60bfbc960924c6c9d9d58432bdd7e67",
            "dddcca469bdc44c0bd692113aa948bf0"
          ]
        },
        "id": "TdjsvefSEsKd",
        "outputId": "867bccc5-1341-4a69-edd2-2d7094f94762"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#####################################################################################################################\n",
            "This python program will use pretrained models and predict if a comment from test dataset is positive or negative \n",
            "#####################################################################################################################\n",
            "\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tInstance --> 1\n",
            "\n",
            "Please select one of the following options : -\n",
            "\t\t\tFor using the predict_gpt2 function please type 1\n",
            "\t\t\tFor using the predict_roberta function please type 2\n",
            "\t\t\tFor using the finetuned_predict_distilbert function please type 3\n",
            "\t\t\tFor quitting the program please type q or Q\n",
            "\n",
            "Please enter your input --> 3\n",
            "Loading Tokenizer and Model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a2e074f85594fba8e55097a3e3c5856",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/15000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3da6a66ddcd4238b1027611781757ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0888f3e360ce46a39637d460d584c61d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "937/937 [==============================] - 881s 911ms/step - loss: 0.1695 - val_loss: 0.0538\n",
            "Epoch 2/5\n",
            "937/937 [==============================] - 856s 914ms/step - loss: 0.0255 - val_loss: 0.0569\n",
            "Epoch 3/5\n",
            "937/937 [==============================] - 872s 931ms/step - loss: 0.0119 - val_loss: 0.0220\n",
            "Epoch 4/5\n",
            "937/937 [==============================] - 873s 931ms/step - loss: 0.0021 - val_loss: 0.0201\n",
            "Epoch 5/5\n",
            "937/937 [==============================] - 869s 927ms/step - loss: 8.0921e-04 - val_loss: 0.0170\n",
            "94/94 [==============================] - 26s 236ms/step\n",
            "The accuracy achieved for predictions is 0.87%\n",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tInstance --> 2\n",
            "\n",
            "Please select one of the following options : -\n",
            "\t\t\tFor using the predict_gpt2 function please type 1\n",
            "\t\t\tFor using the predict_roberta function please type 2\n",
            "\t\t\tFor using the finetuned_predict_distilbert function please type 3\n",
            "\t\t\tFor quitting the program please type q or Q\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-de147b0f0bdb>\u001b[0m in \u001b[0;36m<cell line: 373>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-de147b0f0bdb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t\\t\\tFor quitting the program please type q or Q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nPlease enter your input --> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "\n",
        "    This script allows to utilize pretrained models and finetunes a standard model to predict if a comment from hugging face IMDB Dataset is having a positive or negative sentiment.\n",
        "    There are pertubations created to build a robust model using adversarial training\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "#Importing all required modules\n",
        "\n",
        "import os   #Importing the os Module to fetch the name of the current user using the script\n",
        "#import torch  #Importing the torch Module to predict\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset, DatasetDict #Importing the datasets module to use the hugging face dataset for imdb\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification   #Importing the AutoTokenizer and AutoModelForSequenceClassification to load pretrained model and it's tokenizer\n",
        "from transformers import DistilBertTokenizer, DataCollatorWithPadding, TFAutoModelForSequenceClassification #Importing the DistilBertTokenizer to tokenize input\n",
        "from datasets import DatasetDict, Dataset\n",
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "import random\n",
        "\n",
        "def create_pertubations(texts, tokenizer):\n",
        "\n",
        "    print(\"Size is \" + str(len(texts)))\n",
        "    moded_text = []\n",
        "    #operations = [1, -1, 2, -2, 3, -3]\n",
        "\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    for sentence in inputs['input_ids']:\n",
        "        print(sentence)\n",
        "        #sentence = tokenizer(texts, padding=True, truncation=True)\n",
        "        sentenceLength = int(len(sentence))\n",
        "        print(sentenceLength)\n",
        "        #Create 5 modified texts\n",
        "        for times in range(5):\n",
        "            temp = sentence\n",
        "            for val in range(3):\n",
        "                targetLocation = random.randint(3, 35)\n",
        "                if temp[targetLocation] > 1:\n",
        "                    temp[targetLocation] -= 1 #= temp[targetLocation] + random.choice(operations)\n",
        "            moded_text.append(tokenizer.decode(temp, skip_special_tokens=True))\n",
        "    print(\"New Size is \" + str(len(moded_text)))\n",
        "    return moded_text\n",
        "\n",
        "\n",
        "# Function to perform sentiment analysis with batching\n",
        "def batch_predict_sentiment(texts, tokenizer, model, batch_size=10):\n",
        "    \"\"\"\n",
        "        This function predicts the sentiment for the test dataset using batches to reduce load\n",
        "        Parameters\n",
        "        ----------\n",
        "        arg1 : texts\n",
        "            This is the input test data for which predictions will pop up\n",
        "        arg2 : tokenizer\n",
        "            This is the tokenizer to be used\n",
        "        arg3 : model\n",
        "            This is the model to be used\n",
        "        arg4 : batch_size\n",
        "            This is the desired batch size to be used for predictions. Note it's defaulted to 10 based on performance on a normal machine. One can tweeak the value if memory is available\n",
        "\n",
        "    \"\"\"\n",
        "    moded_values = create_pertubations(texts, tokenizer)\n",
        "\n",
        "    total_texts = len(moded_values)            #Calculate total Length\n",
        "    predicted_sentiments = list()           #Define an empty list\n",
        "\n",
        "    for i in range(0, total_texts, batch_size):   #Perform action in Batches\n",
        "\n",
        "        texts_batch = moded_values[i:i + batch_size]    #Select Batch\n",
        "        inputs = tokenizer(texts_batch, return_tensors=\"pt\", padding=True, truncation=True)  #Using tokenizer gernerate tensors for torch\n",
        "\n",
        "        with torch.no_grad():       #Use model to predict\n",
        "            outputs = model(**inputs)   #Save Results\n",
        "\n",
        "        predicted_classes = torch.argmax(outputs.logits, dim=1).tolist()   #Get Max Vals as correct predictions\n",
        "        predicted_sentiments.extend(predicted_classes)  #Append results to list\n",
        "        print(\"Predicted \" + str(i) + \"elements\")\n",
        "    return predicted_sentiments      #Return list of values\n",
        "\n",
        "# Calculate accuracy\n",
        "def calculate_accuracy(predicted_sentiments, actual_labels):\n",
        "    \"\"\"\n",
        "        This function calculates the accuracy of the models\n",
        "        Parameters\n",
        "        ----------\n",
        "        arg1 : predicted_sentiments\n",
        "            This is the predicted outputs\n",
        "        arg2 : actual_labels\n",
        "            This is the true values\n",
        "\n",
        "    \"\"\"\n",
        "    correct_predictions = sum(1 for pred, label in zip(predicted_sentiments, actual_labels) if pred == label)    #Sum correct predictions\n",
        "    total_predictions = len(actual_labels)    #Get total predictions\n",
        "    accuracy = correct_predictions / total_predictions * 100  #Calculate Accuracy\n",
        "    return accuracy    #Return accuracy\n",
        "\n",
        "\n",
        "def predict_gpt2(test_data):\n",
        "\n",
        "    \"\"\"\n",
        "        This function consumes the input test data and predicts output and accuracy\n",
        "        Parameters\n",
        "        ----------\n",
        "        arg1 : test_data\n",
        "            This is the input test data for which predictions will pop up\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"Loading Tokenizer and Model\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"mnoukhov/gpt2-imdb-sentiment-classifier\")  #Load the tokenizer for gpt2 trained on IMDB Dataset\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"mnoukhov/gpt2-imdb-sentiment-classifier\") #Load the pre-trained hugging face model for gpt2\n",
        "\n",
        "    print(\"Predicting in batches\")\n",
        "    batch_predicted_sentiments = batch_predict_sentiment(test_data['text'], tokenizer, model)   #Run the predictions in batch mode to reduce load on Memory\n",
        "    actual_labels = test_data['label']        #Define True Labels\n",
        "\n",
        "    print(\"Calculating Accuracies\")\n",
        "    accuracy = calculate_accuracy(batch_predicted_sentiments, actual_labels)    #Calculate the Accuracy achieved\n",
        "    print(f\"The accuracy achieved for predictions is {accuracy:.2f}%\")\n",
        "\n",
        "def predict_roberta(test_data):\n",
        "\n",
        "    \"\"\"\n",
        "        This function consumes the input test data and predicts output and accuracy\n",
        "        Parameters\n",
        "        ----------\n",
        "        arg1 : test_data\n",
        "            This is the input test data for which predictions will pop up\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"Loading Tokenizer and Model\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"abhishek/autonlp-imdb-roberta-base-3662644\")  #Load the tokenizer for gpt2 trained on IMDB Dataset\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"abhishek/autonlp-imdb-roberta-base-3662644\") #Load the pre-trained hugging face model for gpt2\n",
        "\n",
        "    print(\"Predicting in batches\")\n",
        "    batch_predicted_sentiments = batch_predict_sentiment(test_data['text'], tokenizer, model)   #Run the predictions in batch mode to reduce load on Memory\n",
        "    actual_labels = test_data['label']        #Define True Labels\n",
        "\n",
        "    print(\"Calculating Accuracies\")\n",
        "    accuracy = calculate_accuracy(batch_predicted_sentiments, actual_labels)    #Calculate the Accuracy achieved\n",
        "    print(f\"The accuracy achieved for predictions is {accuracy:.2f}%\")\n",
        "\n",
        "def create_pertubations(data, tokenizer):\n",
        "    moded_text = []\n",
        "\n",
        "    texts = []\n",
        "    labels = []\n",
        "\n",
        "\n",
        "\n",
        "    for row in data:\n",
        "        texts.append(row['text'])\n",
        "        labels.append(row['label'])\n",
        "\n",
        "    labels = [label for label in labels for _ in range(5)]\n",
        "\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    count = 0\n",
        "    for sentence in inputs['input_ids']:\n",
        "##        count += 1\n",
        "##        print(count)\n",
        "        #sentence = tokenizer(texts, padding=True, truncation=True)\n",
        "        sentenceLength = int(len(sentence))\n",
        "        #print(sentenceLength)\n",
        "        #Create 5 modified texts\n",
        "        for times in range(5):\n",
        "            temp = sentence\n",
        "            for val in range(3):\n",
        "                targetLocation = random.randint(3, 35)\n",
        "                if temp[targetLocation] > 1:\n",
        "                    temp[targetLocation] -= 1 #= temp[targetLocation] + random.choice(operations)\n",
        "            moded_text.append(tokenizer.decode(temp, skip_special_tokens=True))\n",
        "##    print(\"New Size is \" + str(len(moded_text)))\n",
        "\n",
        "    data_dict = {\"text\": moded_text, \"label\": labels}\n",
        "\n",
        "    dataset = Dataset.from_dict(data_dict)\n",
        "\n",
        "    ##text_dataset = Dataset.from_dict(moded_text)\n",
        "    #label_dataset = Dataset.from_dict(labels)\n",
        "    ##dataset = Dataset.from_dict({\"text\": texts, \"label\": labels})\n",
        "    #dataset = dataset.set_format(type='torch')  # Set the format if you're using PyTorch\n",
        "    #dataset.metadata = {\"features\": [\"text\", \"label\"], \"num_rows\": 1500}\n",
        "    #dataset_dict = DatasetDict({\"text\": text_dataset, \"label\": label_dataset})\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def finetuned_predict_distilbert(imdb):\n",
        "    \"\"\"\n",
        "        This function consumes an input file and finetunes the pretrained word2vec model\n",
        "        Parameters\n",
        "        ----------\n",
        "        arg1 : path_to_train_file\n",
        "            This is the input filename\n",
        "\n",
        "    \"\"\"\n",
        "    print(\"Loading Tokenizer and Model\")\n",
        "\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")     #Load the tokenizer for distilbert trained on IMDB Dataset\n",
        "    model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)      #Load the pre-trained hugging face model for distilbert\n",
        "\n",
        "    small_train_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(3000))])\n",
        "    small_val_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(300))])\n",
        "    small_test_dataset = imdb[\"test\"].shuffle(seed=42).select([i for i in list(range(300))])\n",
        "\n",
        "    moded_train_dataset = create_pertubations(small_train_dataset, tokenizer)\n",
        "    moded_val_dataset = create_pertubations(small_val_dataset, tokenizer)\n",
        "    moded_test_dataset = create_pertubations(small_test_dataset, tokenizer)\n",
        "\n",
        "    small_dataset_dict = DatasetDict({\n",
        "                'train': moded_train_dataset,\n",
        "                'validation': moded_val_dataset,\n",
        "                'test': moded_test_dataset\n",
        "            })\n",
        "##    moded_values = create_pertubations(data, tokenizer)\n",
        "\n",
        "    def preprocess_function(examples):\n",
        "        return tokenizer(examples[\"text\"], truncation=True)             #Using a function to map the whole dataset across train, test and validation\n",
        "\n",
        "    tokenized_imdb = small_dataset_dict.map(preprocess_function, batched=True)        #Mapping the data with the tokenizer\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")    #Using data collator to capture the fields\n",
        "    accuracy = evaluate.load(\"accuracy\")    #Using accuracy for computing metrics\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "        return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "    #Defining important hyper parameters\n",
        "    batch_size = 16\n",
        "    num_epochs = 6\n",
        "    batches_per_epoch = len(tokenized_imdb[\"train\"]) // batch_size\n",
        "    total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "    optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)\n",
        "\n",
        "    #Converting to tensor-flow sets for input requirement\n",
        "    tf_train_set = model.prepare_tf_dataset(\n",
        "        tokenized_imdb[\"train\"],\n",
        "        shuffle=True,\n",
        "        batch_size=16,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        "\n",
        "    tf_validation_set = model.prepare_tf_dataset(\n",
        "        tokenized_imdb[\"validation\"],\n",
        "        shuffle=False,\n",
        "        batch_size=16,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        "\n",
        "    tf_test_set = model.prepare_tf_dataset(\n",
        "        tokenized_imdb[\"test\"],\n",
        "        shuffle=False,\n",
        "        batch_size=16,\n",
        "        collate_fn=data_collator,\n",
        "    )\n",
        "\n",
        "    #Compiling model based on previous additions\n",
        "    model.compile(optimizer=optimizer)\n",
        "\n",
        "    #Using Keras Metrics for Call Backs and traing the models for 5 epochs\n",
        "    metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)\n",
        "    model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=5, verbose = True)\n",
        "\n",
        "    #predicting the results\n",
        "    results = model.predict(tf_test_set)\n",
        "\n",
        "    #Fetching max values for correct labels\n",
        "    predicted_labels = np.argmax(results['logits'], axis=1)\n",
        "\n",
        "    #Get the accuracy\n",
        "    accuracy = np.mean(predicted_labels == small_dataset_dict['test']['label'])\n",
        "    print(f\"The accuracy achieved for predictions is {accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    \"\"\"\n",
        "        This is the main function that controls the execution of the script. The user is prompted to choose from a menu to either select a function or exit script\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #Printing a welcome screen Message\n",
        "   # print('\\t\\t\\t\\t\\t\\t!! Welcome ' + os.getlogin() + ' !!')\n",
        "    print('#####################################################################################################################')\n",
        "    print('This python program will use pretrained models and predict if a comment from test dataset is positive or negative ')\n",
        "    print('#####################################################################################################################\\n')\n",
        "\n",
        "\n",
        "    #Instancing the variables\n",
        "    blRun = True                                                                                        #Creating a boolean Flag to control the while loop execution. By default the value is set as True\n",
        "    nInst = 1                                                                                           #Creating a integer type variable to count the number of times the while loop was executed\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    while(blRun):                                                                                       #While the boolean condition is true run the loop else exit\n",
        "        print('\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tInstance --> ' + str(nInst))\n",
        "        print('\\nPlease select one of the following options : -')\n",
        "\n",
        "        print('\\t\\t\\tFor using the predict_gpt2 function please type 1')\n",
        "        print('\\t\\t\\tFor using the predict_roberta function please type 2')\n",
        "        print('\\t\\t\\tFor using the finetuned_predict_distilbert function please type 3')\n",
        "        print('\\t\\t\\tFor quitting the program please type q or Q')\n",
        "\n",
        "        choice = input('\\nPlease enter your input --> ')\n",
        "\n",
        "        if choice == '1':\n",
        "\n",
        "            imdb = load_dataset(\"imdb\")\n",
        "            small_test_dataset = imdb[\"test\"].shuffle(seed=42).select(range(200))\n",
        "\n",
        "            predict_gpt2(small_test_dataset)\n",
        "\n",
        "        elif choice == '2':\n",
        "\n",
        "            imdb = load_dataset(\"imdb\")\n",
        "            small_test_dataset = imdb[\"test\"].shuffle(seed=42).select(range(200))\n",
        "\n",
        "            predict_roberta(small_test_dataset)\n",
        "\n",
        "        elif choice == '3':\n",
        "\n",
        "            imdb = load_dataset(\"imdb\")\n",
        "##            print(imdb)\n",
        "##            small_train_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(3000))])\n",
        "##            small_val_dataset = imdb[\"train\"].shuffle(seed=42).select([i for i in list(range(300))])\n",
        "##            small_test_dataset = imdb[\"test\"].shuffle(seed=42).select([i for i in list(range(300))])\n",
        "##\n",
        "##            small_dataset_dict = DatasetDict({\n",
        "##                'train': small_train_dataset,\n",
        "##                'validation': small_val_dataset,\n",
        "##                'test': small_test_dataset\n",
        "##            })\n",
        "\n",
        "            finetuned_predict_distilbert(imdb)\n",
        "\n",
        "        elif (choice == 'q' or choice == 'Q'):\n",
        "   #         print(\"Thankyou \" + os.getlogin() + \" for trying out the program.\\n You have tried out this program for \" + str(nInst) + \" time/s. \\nHave a nice day!!\\n\")\n",
        "            blRun = False\n",
        "\n",
        "        else:\n",
        "          print(\"\\n!!!!!!!!!!!!!!!Invalid Input!!!!!!!!!!!!!!!\\n Please check the input choice.\\n\")\n",
        "\n",
        "        nInst += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrjngQBdljVM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0888f3e360ce46a39637d460d584c61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c41a5d3a1894f1db4f903e5c98b172c",
              "IPY_MODEL_71e84a3643f54ad2942d931c06037f38",
              "IPY_MODEL_ac29afc81d524eccb5749d65edbf703d"
            ],
            "layout": "IPY_MODEL_8d37784e34fd42cf8efb71260cdc27e5"
          }
        },
        "0c41a5d3a1894f1db4f903e5c98b172c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bc4f82403ba4591bcb7c2d5b162c1a0",
            "placeholder": "​",
            "style": "IPY_MODEL_0e96e5d9810d45f386d4431c1eab815f",
            "value": "Map: 100%"
          }
        },
        "0e96e5d9810d45f386d4431c1eab815f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3213eae0f2ad416bbf6d708363bd910d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff4bfe10dc6247d0a0b516be82df087d",
            "placeholder": "​",
            "style": "IPY_MODEL_6ed9bcc8ae8c4f019ff212c54a9f9208",
            "value": "Map: 100%"
          }
        },
        "41efd05011c44826ad0ad60ad677fecc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4329fbef8fd044839b19df6f564315b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b455ef61e1c746f3a7d6f21af943059b",
            "placeholder": "​",
            "style": "IPY_MODEL_61f9b83753754282951ed99efb97278a",
            "value": "Map: 100%"
          }
        },
        "53903f01046d46c0b7422c0750625de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8483462bb8f94f0dbe62c11b319b311d",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_844145daecd54108bdc9bae803c23b41",
            "value": 1500
          }
        },
        "5bc4f82403ba4591bcb7c2d5b162c1a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dc9169fbcc047bdb49b0e641391fa30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f9b83753754282951ed99efb97278a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ed9bcc8ae8c4f019ff212c54a9f9208": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fa771f3f04e4366bbd4e1699bf413d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f032b765cbf14b9b895b98a37888fac8",
            "placeholder": "​",
            "style": "IPY_MODEL_9dd27d136c164798b812b8d1abc10e89",
            "value": " 1500/1500 [00:06&lt;00:00, 238.97 examples/s]"
          }
        },
        "71e84a3643f54ad2942d931c06037f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94307407414f4dc1b2a1457b3cd105c2",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dadf4c8a87f148f2aa891e369ec104a5",
            "value": 1500
          }
        },
        "8387dbcf27fc4d6eb7c90ab9feb29486": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "844145daecd54108bdc9bae803c23b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8483462bb8f94f0dbe62c11b319b311d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c57c3b6962c4028ac703d9ce6df74d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd25f2e1d9ba4807b78d392893539621",
            "placeholder": "​",
            "style": "IPY_MODEL_8387dbcf27fc4d6eb7c90ab9feb29486",
            "value": " 15000/15000 [01:09&lt;00:00, 207.59 examples/s]"
          }
        },
        "8d37784e34fd42cf8efb71260cdc27e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94307407414f4dc1b2a1457b3cd105c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a2e074f85594fba8e55097a3e3c5856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4329fbef8fd044839b19df6f564315b2",
              "IPY_MODEL_a5ba9cf403ec4b08a813235785ab0083",
              "IPY_MODEL_8c57c3b6962c4028ac703d9ce6df74d9"
            ],
            "layout": "IPY_MODEL_b3968415d12b40438094e671ae3f8031"
          }
        },
        "9dd27d136c164798b812b8d1abc10e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3da6a66ddcd4238b1027611781757ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3213eae0f2ad416bbf6d708363bd910d",
              "IPY_MODEL_53903f01046d46c0b7422c0750625de9",
              "IPY_MODEL_6fa771f3f04e4366bbd4e1699bf413d3"
            ],
            "layout": "IPY_MODEL_5dc9169fbcc047bdb49b0e641391fa30"
          }
        },
        "a5ba9cf403ec4b08a813235785ab0083": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41efd05011c44826ad0ad60ad677fecc",
            "max": 15000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcabe035fc5e42f99b1dd925d0b49703",
            "value": 15000
          }
        },
        "a60bfbc960924c6c9d9d58432bdd7e67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac29afc81d524eccb5749d65edbf703d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a60bfbc960924c6c9d9d58432bdd7e67",
            "placeholder": "​",
            "style": "IPY_MODEL_dddcca469bdc44c0bd692113aa948bf0",
            "value": " 1500/1500 [00:06&lt;00:00, 221.83 examples/s]"
          }
        },
        "b3968415d12b40438094e671ae3f8031": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b455ef61e1c746f3a7d6f21af943059b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd25f2e1d9ba4807b78d392893539621": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dadf4c8a87f148f2aa891e369ec104a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dddcca469bdc44c0bd692113aa948bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f032b765cbf14b9b895b98a37888fac8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcabe035fc5e42f99b1dd925d0b49703": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff4bfe10dc6247d0a0b516be82df087d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
